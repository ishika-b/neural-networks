{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnfl_assn2_q2.ipynb",
      "provenance": [],
      "mount_file_id": "11fRG4O4ILSIsOwEZwurUWp-ZBCM4m1ae",
      "authorship_tag": "ABX9TyMBHfPfmsVrvF2qr4tgm91p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishika-b/neural-networks/blob/main/nnfl_assn2_q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6uoxCoi1_tU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzsaJOhR4t5f"
      },
      "source": [
        "def k(u,v):\n",
        "  d = 2\n",
        "  return (np.dot(u,v)+1)**d\n",
        "\n",
        "def k_rbf(u,v):\n",
        "  #sigma = 1 \n",
        "  return np.exp((-1/2)*np.linalg.norm(u-v)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmLEn5-O2jRD"
      },
      "source": [
        "def train(x,y):\n",
        " #misclassification counter\n",
        " alpha = np.zeros((x.shape[0],1)) #1x70 the columns are the instances \n",
        " iter = 20\n",
        " y_pred = np.zeros((y.shape))\n",
        "\n",
        " for t in range(iter):\n",
        "   for j in range(x.shape[0]):\n",
        "     sum =  0\n",
        "     for i in range(x.shape[0]):\n",
        "       sum = sum + alpha[i]*y[i]*k(x[i],x[j])\n",
        "     y_pred[j] = np.sign(sum)\n",
        "     if (y_pred[j] != y[j]):\n",
        "       alpha[j] = alpha[j] + 1\n",
        "\n",
        " return alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnfIsQTVZ8UI"
      },
      "source": [
        "def train_rbf(x,y):\n",
        "  #misclassification counter\n",
        "  alpha = np.zeros((x.shape[0],1)) #1x70 the columns are the instances \n",
        "  iter = 20\n",
        "  y_pred = np.zeros((y.shape))\n",
        "\n",
        "  for t in range(iter):\n",
        "    for j in range(x.shape[0]):\n",
        "      sum =  0\n",
        "      for i in range(x.shape[0]):\n",
        "        sum = sum + alpha[i]*y[i]*k_rbf(x[i],x[j])\n",
        "      y_pred[j] = np.sign(sum)\n",
        "      if (y_pred[j] != y[j]):\n",
        "        alpha[j] = alpha[j] + 1\n",
        "\n",
        "  return alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXC11jy4aLw_"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  data = pd.read_excel('/content/drive/My Drive/nnfl/nnfl2/data55.xlsx', sheet_name='Sheet1',header=None)\n",
        "  data_shuffled = data.sample(frac=1).reset_index(drop=True)\n",
        "  \n",
        "  x = np.zeros((100,4))\n",
        "  y = np.zeros((100,1))\n",
        "\n",
        "  for i in range(100):\n",
        "   x[i][0] = data_shuffled[0][i]\n",
        "   x[i][1] = data_shuffled[1][i]\n",
        "   x[i][2] = data_shuffled[2][i]\n",
        "   x[i][3] = data_shuffled[3][i]\n",
        "\n",
        "   y[i][0] = data_shuffled[4][i]\n",
        "  \n",
        "  for i in range(4):\n",
        "    mean = np.mean(x[:,i]) \n",
        "    std = np.std(x[:,i])\n",
        "    x[:,i] = [(a-mean)/std for a in x[:,i]]\n",
        "\n",
        "  for i in range(y.shape[0]):\n",
        "    if (y[i] == 0):\n",
        "      y[i] = -1\n",
        "\n",
        " # train test and validation split  \n",
        "  x_train = x[0:70][:]\n",
        "  x_val =  x[70:80][:]\n",
        "  x_test = x[80:100][:]\n",
        "  y_train = y[0:70][:]\n",
        "  y_val =  y[70:80][:]\n",
        "  y_test = y[80:100][:]  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1ccbVwxadVD"
      },
      "source": [
        "POLYNOMIAL KERNEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONypYE7T2mGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d289a0cc-a2ab-43f4-9350-bebb9cf49665"
      },
      "source": [
        "  misclass_ctr = train(x_train,y_train)\n",
        "\n",
        "  predictions = np.zeros((y_test.shape))\n",
        "  for j in range(x_test.shape[0]):\n",
        "    sum =  0\n",
        "    for i in range(x_train.shape[0]):\n",
        "      sum = sum + misclass_ctr[i]*y_test[j]*k(x_test[j],x_train[i])\n",
        "    predictions[j] = np.sign(sum)\n",
        "\n",
        "  #print(predictions)\n",
        "  #print(y_test)\n",
        "  \n",
        "  correct_arr = [1 if (a == b ) else 0 for (a, b) in zip(predictions, y_test)] \n",
        "  sensitivity_arr = []\n",
        "  specificity_arr = []\n",
        "  \n",
        "  for i in range(y_test.shape[0]):\n",
        "    if (predictions[i] == 1 and y_test[i]==1):\n",
        "      sensitivity_arr.append(1)\n",
        "    elif (predictions[i]==-1 and y_test[i]==1):\n",
        "      sensitivity_arr.append(0)\n",
        "    if (predictions[i] == -1 and y_test[i]== -1):\n",
        "      specificity_arr.append(1)\n",
        "    elif (predictions[i]==1 and y_test[i]== -1):\n",
        "      specificity_arr.append(0)\n",
        "    \n",
        "  acc = np.sum(correct_arr)/len(correct_arr) \n",
        "  sens = np.sum(sensitivity_arr)/len(sensitivity_arr)\n",
        "  spec = np.sum(specificity_arr)/len(specificity_arr)\n",
        "\n",
        "  print(\"accuracy:\",acc)\n",
        "  print(\"sensitivity:\",sens)\n",
        "  print(\"specificity:\",spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 1.0\n",
            "sensitivity: 1.0\n",
            "specificity: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ_CZscIbeDm"
      },
      "source": [
        "RBF KERNEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH4bZkb0bhRG",
        "outputId": "82827403-1e9a-4d88-fc6a-b4f3d2b7b336"
      },
      "source": [
        "  misclass_ctr = train_rbf(x_train,y_train)\n",
        "\n",
        "  predictions = np.zeros((y_test.shape))\n",
        "  for j in range(x_test.shape[0]):\n",
        "    sum =  0\n",
        "    for i in range(x_train.shape[0]):\n",
        "      sum = sum + misclass_ctr[i]*y_test[j]*k_rbf(x_test[j],x_train[i])\n",
        "    predictions[j] = np.sign(sum)\n",
        "\n",
        "  #print(predictions)\n",
        "  #print(y_test)\n",
        "  \n",
        "  correct_arr = [1 if (a == b ) else 0 for (a, b) in zip(predictions, y_test)] \n",
        "  sensitivity_arr = []\n",
        "  specificity_arr = []\n",
        "  \n",
        "  for i in range(y_test.shape[0]):\n",
        "    if (predictions[i] == 1 and y_test[i]==1):\n",
        "      sensitivity_arr.append(1)\n",
        "    elif (predictions[i]==-1 and y_test[i]==1):\n",
        "      sensitivity_arr.append(0)\n",
        "    if (predictions[i] == -1 and y_test[i]== -1):\n",
        "      specificity_arr.append(1)\n",
        "    elif (predictions[i]==1 and y_test[i]== -1):\n",
        "      specificity_arr.append(0)\n",
        "    \n",
        "  acc = np.sum(correct_arr)/len(correct_arr) \n",
        "  sens = np.sum(sensitivity_arr)/len(sensitivity_arr)\n",
        "  spec = np.sum(specificity_arr)/len(specificity_arr)\n",
        "\n",
        "  print(\"accuracy:\",acc)\n",
        "  print(\"sensitivity:\",sens)\n",
        "  print(\"specificity:\",spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 1.0\n",
            "sensitivity: 1.0\n",
            "specificity: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}