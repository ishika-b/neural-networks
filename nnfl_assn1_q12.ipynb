{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnfl_assn1_q12.ipynb",
      "provenance": [],
      "mount_file_id": "1iUr8IF-vl_pQTh5d_OJCCZ47KjmywXls",
      "authorship_tag": "ABX9TyOUtf+OziswGSD3vtVg1SA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishika-b/neural-networks/blob/main/nnfl_assn1_q12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cNXp4L2oIIT"
      },
      "source": [
        "import random \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOHtXzv7poST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "58ef2695-07eb-4490-e5f6-92e4cbae5e3c"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Read dataset and convert to numpy array\n",
        "    df = pd.read_excel(\"/content/drive/My Drive/nnfl/nnfl/data4.xlsx\",header=None,sheet_name=\"Sheet1\")\n",
        "    data = np.array(df)\n",
        "\n",
        "    shuffle_df = df.sample(frac=1)\n",
        "\n",
        "    train_size = int(round(0.7 * len(df)))\n",
        "    train_set = shuffle_df[:train_size]\n",
        "    test_set = shuffle_df[train_size:]\n",
        "    X_train = train_set.iloc[:,[0,1,2,3,4,5,6]].values\n",
        "    y_train = train_set.iloc[:,[7]].values-1 #the minus one changes class labels to 0 and 1\n",
        "    X_test =  test_set.iloc[:,[0,1,2,3,4,5,6]].values\n",
        "    y_test = test_set.iloc[:,[7]].values-1 #the minus one changes class labels to 0 and 1\n",
        "\n",
        "    n_classes = len(np.unique(y_test))\n",
        "  \n",
        "    y_test = list(y_test)  \n",
        "    dist_test = [y_test.count(class_label) for class_label in range(n_classes)]\n",
        "    print(dist_test) #test instance classes\n",
        "\n",
        "    y_train = list(y_train)  \n",
        "    dist_train = [y_train.count(class_label) for class_label in range(n_classes)]\n",
        "    print(dist_train) #training instance classes\n",
        "\n",
        "    prob_y_train = [dist/len(y_train) for dist in dist_train] #probability of each class in training data\n",
        "   \n",
        "    mean_tr = []\n",
        "    covar_tr = []\n",
        "    for i in range(n_classes): #taking i = 0 first\n",
        "        X_temp = []\n",
        "        for j in range(X_train.shape[0]): #loop over the number of training instances \n",
        "            if y_train[j] == i: #check if it's 0 \n",
        "                X_temp.append(X_train[j]) #append to x_temp \n",
        "        X_temp = np.array(X_temp) #convert to np.array (has all the training instances of class = 0)\n",
        "        mean_tr.append(np.mean(X_temp, axis=0)) #mean of each feature for all instances with class = 0 (4 means for 4 feature vectors)\n",
        "        covar_tr.append(np.cov(X_temp.T)) #shows the covariance between x1,x2,x3,x4 and how they vary with each other\n",
        "\n",
        "    correct = 0 \n",
        "    class_y_correct = np.zeros(n_classes)\n",
        "\n",
        "    for j in range(X_test.shape[0]): #number of instances in x_test\n",
        "       #maximum likelihood estimator for multivariate gaussian distribution:\n",
        "        likelihood = [1/((2 * 22/7)**2*(np.linalg.det(covar_tr[i]))**0.5)*np.exp(-0.5*(np.transpose(X_test[j] - mean_tr[i]).dot(np.linalg.inv(covar_tr[i])).dot(X_test[j] - mean_tr[i]))) for i in range(n_classes)]\n",
        "        y_pred = np.argmax(likelihood)\n",
        "\n",
        "        if y_pred == y_test[j]:\n",
        "            class_y_correct[y_pred] += 1 #correctly predicted class goes up by one\n",
        "            correct += 1 #total number correct goes up by 1\n",
        "        \n",
        "    for i in range(n_classes):\n",
        "        class_accuracy= class_y_correct[i]/dist_test[i]\n",
        "        print(\"class accuracy:\",class_accuracy)\n",
        "    print(\"overall accuracy:\",correct/len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11, 16, 18]\n",
            "[39, 34, 32]\n",
            "class accuracy: 1.0\n",
            "class accuracy: 0.875\n",
            "class accuracy: 0.9444444444444444\n",
            "overall accuracy: 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}